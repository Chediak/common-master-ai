{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2d4Kt0TXjW2B56Qo28Ww5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chediak/common-master-ai/blob/main/prodesan_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y1cGJfDVKHzU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "d09669ce-cfbe-4ac1-bb41-b5a6d01d9689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (0.11.4)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.9.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (11.0.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (4.30.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.13.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting pt-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.7.0/pt_core_news_sm-3.7.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from pt-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.13.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (0.115.5)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (0.32.0)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.41.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.9.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.23.4)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.42.0,>=0.40.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.2.2)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (0.0.17)\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfplumber sentence-transformers faiss-cpu spacy\n",
        "!python -m spacy download pt_core_news_sm\n",
        "!pip install fastapi uvicorn\n",
        "!pip install python-multipart"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "import spacy\n",
        "import json\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        pages = [page.extract_text() for page in pdf.pages]\n",
        "    return pages\n",
        "\n",
        "def preprocess_and_split_text(pages):\n",
        "    news_items = [item.strip() for page in pages for item in page.split(\"\\n\\n\") if item.strip()]\n",
        "    return news_items\n",
        "\n",
        "def generate_embeddings(news_items, model_name='all-MiniLM-L6-v2'):\n",
        "    model = SentenceTransformer(model_name)\n",
        "    embeddings = model.encode(news_items)\n",
        "    return embeddings, model\n",
        "\n",
        "def create_faiss_index(embeddings):\n",
        "    dimension = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(dimension)\n",
        "    index.add(embeddings)\n",
        "    return index\n",
        "\n",
        "def add_metadata(news_items):\n",
        "    metadata = [{\"id\": i, \"content\": news_items[i], \"length\": len(news_items[i])} for i in range(len(news_items))]\n",
        "    return metadata\n",
        "\n",
        "def extract_entities(news_items):\n",
        "    nlp = spacy.load(\"pt_core_news_sm\")\n",
        "    extracted_data = []\n",
        "    for idx, news in enumerate(news_items):\n",
        "        doc = nlp(news)\n",
        "        entities = {\"id\": idx, \"content\": news, \"dates\": [], \"names\": [], \"organizations\": []}\n",
        "\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ == \"DATE\":\n",
        "                entities[\"dates\"].append(ent.text)\n",
        "            elif ent.label_ == \"PERSON\":\n",
        "                entities[\"names\"].append(ent.text)\n",
        "            elif ent.label_ == \"ORG\":\n",
        "                entities[\"organizations\"].append(ent.text)\n",
        "\n",
        "        cnpj_matches = re.findall(r\"\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2}\", news)\n",
        "        entities[\"cnpjs\"] = cnpj_matches\n",
        "        extracted_data.append(entities)\n",
        "    return extracted_data\n",
        "\n",
        "def create_structured_index(entities):\n",
        "    index = {\"dates\": {}, \"names\": {}, \"organizations\": {}, \"cnpjs\": {}}\n",
        "    for item in entities:\n",
        "        for date in item[\"dates\"]:\n",
        "            index[\"dates\"].setdefault(date, []).append(item)\n",
        "        for name in item[\"names\"]:\n",
        "            index[\"names\"].setdefault(name, []).append(item)\n",
        "        for org in item[\"organizations\"]:\n",
        "            index[\"organizations\"].setdefault(org, []).append(item)\n",
        "        for cnpj in item[\"cnpjs\"]:\n",
        "            index[\"cnpjs\"].setdefault(cnpj, []).append(item)\n",
        "    return index\n",
        "\n",
        "def query_index(index, query_type, query_value):\n",
        "    if query_type in index:\n",
        "        return index[query_type].get(query_value, [])\n",
        "    return []\n",
        "\n",
        "def optimize_layout(metadata, top_k=5):\n",
        "    sorted_news = sorted(metadata, key=lambda x: x[\"length\"], reverse=True)\n",
        "    layout = []\n",
        "    for i, item in enumerate(sorted_news):\n",
        "        layout.append({\n",
        "            \"type\": \"news\",\n",
        "            \"content\": item[\"content\"],\n",
        "            \"page\": i // top_k + 1,\n",
        "            \"position\": i % top_k\n",
        "        })\n",
        "        if (i + 1) % 3 == 0:\n",
        "            layout.append({\n",
        "                \"type\": \"advertisement\",\n",
        "                \"content\": \"Ad Placeholder\",\n",
        "                \"page\": (i + 1) // top_k + 1,\n",
        "                \"position\": \"bottom\"\n",
        "            })\n",
        "    return layout\n",
        "\n",
        "def main():\n",
        "    pdf_path = \"/content/RHOAI _ Prodesp - Diário Oficial.pdf\"\n",
        "\n",
        "    print(\"Extracting text from PDF...\")\n",
        "    pages = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "    print(\"Preprocessing and splitting text...\")\n",
        "    news_items = preprocess_and_split_text(pages)\n",
        "\n",
        "    print(\"Generating embeddings...\")\n",
        "    embeddings, model = generate_embeddings(news_items)\n",
        "\n",
        "    print(\"Creating FAISS index...\")\n",
        "    index = create_faiss_index(np.array(embeddings))\n",
        "\n",
        "    print(\"Adding metadata...\")\n",
        "    metadata = add_metadata(news_items)\n",
        "\n",
        "    print(\"Extracting entities...\")\n",
        "    entities = extract_entities(news_items)\n",
        "\n",
        "    print(\"Creating structured index...\")\n",
        "    structured_index = create_structured_index(entities)\n",
        "\n",
        "    print(\"Querying by date '13/11/2024'...\")\n",
        "    date_results = query_index(structured_index, \"dates\", \"13/11/2024\")\n",
        "    print(json.dumps(date_results, indent=2))\n",
        "\n",
        "    print(\"Querying by organization 'ARAUJO E REPLANDE LTDA'...\")\n",
        "    org_results = query_index(structured_index, \"organizations\", \"ARAUJO E REPLANDE LTDA\")\n",
        "    print(json.dumps(org_results, indent=2))\n",
        "\n",
        "    print(\"Optimizing layout...\")\n",
        "    layout = optimize_layout(metadata)\n",
        "    print(json.dumps(layout, indent=2))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "4v3uaYf4KIxT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab6ce2bc-2394-4068-d98c-264541883eff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting text from PDF...\n",
            "Preprocessing and splitting text...\n",
            "Generating embeddings...\n",
            "Creating FAISS index...\n",
            "Adding metadata...\n",
            "Extracting entities...\n",
            "Creating structured index...\n",
            "Querying by date '13/11/2024'...\n",
            "[]\n",
            "Querying by organization 'ARAUJO E REPLANDE LTDA'...\n",
            "[]\n",
            "Optimizing layout...\n",
            "[\n",
            "  {\n",
            "    \"type\": \"news\",\n",
            "    \"content\": \"EstruturadoJSONderetornoesperadoqueser\\u00e1geradopelaRedHat\\n{ \\\"pdf_data\\\":\\n[\\n{\\\"id\\\": \\u201cf97fb8c9-60d6-4fed-a82d-1cdf4e8be0bc\\u201d ,\\\"x\\\":50,\\\"y\\\":300,\\\"pagina\\\":1,\\\"tipo\\\":\\\"mat\\u00e9ria\\\"},\\n{\\u201cid\\u201d:\\u201c\\\",\\\"x\\\":100,\\\"y\\\":550,\\\"pagina\\\":1,\\\"tipo\\\":\\\"titulo\\\"},\\n{\\u201cid\\u201d:\\u201cd2a7e6bd-5d6d-4e1c-a747-a0ae5f1499da\\\",\\\"x\\\":100,\\\"y\\\":550,\\\"pagina\\\":1,\\\"tipo\\\":\\\"mat\\u00e9ria\\\"}\\n{\\u201cid\\u201d:\\u201c\\\",\\\"x\\\":100,\\\"y\\\":550,\\\"pagina\\\":1,\\\"tipo\\\":\\\"calhau-1\\\"}\\n]\\n}\\n\\u2014--------\\nDi\\u00e1riooficial:tamanhoA3\\n-Alinhamentodasmat\\u00e9riascomamargemsuperiorquandonaprimeiralinhainterpretando\\n\\\"Alinhamento\\\"comodist\\u00e2nciadamargemsuperior:17mm.\\n-Alinhamentodasmat\\u00e9riascomamargeminferiorquandonaultimalinha,interpretando\\\"Alinhamento\\\"\\ncomodist\\u00e2nciadamargeminferior:13mm.\\n-Alinhamentodasmat\\u00e9riascomamargemesquerdaquandonaprimeiracolunainterpretando\\n\\\"Alinhamento\\\"comodist\\u00e2nciadamargemesquerda:13mm\\n-Alinhamentodasmat\\u00e9riascomamargemdireitaquandonaultimacoluna,interpretando\\n\\\"Alinhamento\\\"comodist\\u00e2nciadamargemdireita:13mm.\\n5\",\n",
            "    \"page\": 1,\n",
            "    \"position\": 0\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"news\",\n",
            "    \"content\": \"Contatos Red Hat\\nContatoRedHat Nome E-mail\\nAccountManager Pedro Ganem Filho pedroganem@redhat.com\\nSolutionArchitect Juarez J\\u00fanior jjunior@redhat.com\\nTerritoryServicesManager Rejane Rossi rrossi@redhat.com\\nArchitect Tarcisio Oliveira tarcisio@redhat.com\\nSSP Gabriel Sampaio gsampaio@redhat.com\\nSSP Joao Jose Silva (JJ) joao.silva@redhat.com\\nSSA Weslley Rosalem wrosalem@redhat.com\\nHist\\u00f3rico do Documento\\nVers\\u00e3o Data Respons\\u00e1vel Observa\\u00e7\\u00e3o\\n1.0 10-11-2024 Tarcisio Oliveira Elabora\\u00e7\\u00e3ododocumento\\n3\",\n",
            "    \"page\": 1,\n",
            "    \"position\": 1\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"news\",\n",
            "    \"content\": \"-Espa\\u00e7amentominimoentreosblocosdemat\\u00e9riasde5CM-\\nCorre\\u00e7\\u00e3o:Espa\\u00e7amentom\\u00ednimoentreasmat\\u00e9riasmaisutilizado\\u00e9deaproximadamente5MM\\n(mil\\u00edmetros)\\n-Adi\\u00e7\\u00e3odecalhauautomaticamente-Bibliotecazipadaemanexo\\n-Ocalhauser\\u00e1adicionadoautomaticamenteSE,esomenteSE,oespa\\u00e7ovagoformenorqueos\\ncalhausdispon\\u00edveis\\n-Verificarostamanhosdispon\\u00edveisdecalhaus\\nPrincipaismedidasemmil\\u00edmetrosparapublicidade\\nLxA\\n81x100\\n81x400\\n250x40\\n250x120\\n250x200\\n250x210\\n250x294\\n250x370\\n6\",\n",
            "    \"page\": 1,\n",
            "    \"position\": 2\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"advertisement\",\n",
            "    \"content\": \"Ad Placeholder\",\n",
            "    \"page\": 1,\n",
            "    \"position\": \"bottom\"\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"news\",\n",
            "    \"content\": \"1. Red Hat OpenShift Container Platform\\n2. Red Hat OpenShift AI\\n3. Diagrama\\u00e7\\u00e3o\\na. Arquitetura\\n#TODO\\nb. Protocolo\\n{ \\\"pdf_data\\\":\\n[\\n{\\\"id\\\": \\u201cf97fb8c9-60d6-4fed-a82d-1cdf4e8be0bc\\u201d , \\u201caltura\\u201d:125,\\u201clargura\\u201d:35,\\n\\\"agrupamento\\\":1},\\n{\\\"id\\\": \\u201cf97fb8c9-60d6-4fed-a82d-1cdf4e8be0bc\\u201d , \\u201caltura\\u201d:70,\\u201clargura\\u201d:40,\\n\\\"agrupamento\\\":2}\\n]\\n}\\n4\",\n",
            "    \"page\": 1,\n",
            "    \"position\": 3\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"news\",\n",
            "    \"content\": \"b. Protocolo\\n#TODO\\n5. #TODO\\nVmwarevsocpvirt\\nExpandirarquitetura?\\n6.#TODO\\nTermos:\\nAdmite/Admitindo\\nAposenta\\nAposentado\\nAposentadoria\\nAposentando\\nAposentar\\nDemite/Demiss\\u00e3o\\nEfetiva\\nExonera\\nExonera\\u00e7\\u00e3o\\nExpuls\\u00e3o\\nFalecidos\\nFalecimento\\nNomea\\u00e7\\u00e3o\\nNomeia/Nomeando\\nReintegra\\n8\",\n",
            "    \"page\": 1,\n",
            "    \"position\": 4\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"news\",\n",
            "    \"content\": \"Sum\\u00e1rio\\nSum\\u00e1rio 2\\nContatos Red Hat 3\\nHist\\u00f3rico do Documento 3\\n1. Red Hat OpenShift Container Platform 4\\n2. Red Hat OpenShift AI 4\\n3. Diagrama\\u00e7\\u00e3o 4\\n4. Extra\\u00e7\\u00e3o 5\\n5. #TODO 5\\n2\",\n",
            "    \"page\": 2,\n",
            "    \"position\": 0\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"advertisement\",\n",
            "    \"content\": \"Ad Placeholder\",\n",
            "    \"page\": 2,\n",
            "    \"position\": \"bottom\"\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"news\",\n",
            "    \"content\": \"-Justificarasmat\\u00e9riasqueest\\u00e3odentrodamesmacolunaautomaticamente\\n10.Entreasse\\u00e7\\u00f5esdemat\\u00e9ria,incluirumtextoautomaticamentedaquebradese\\u00e7\\u00e3o\\n4.Extra\\u00e7\\u00e3o\\na. Arquitetura\\n#TODO\\n7\",\n",
            "    \"page\": 2,\n",
            "    \"position\": 1\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"news\",\n",
            "    \"content\": \"Suspende\\nCertid\\u00e3ode\\u00f3bito\\nExonerando\\nDesignando\\nDesigna\\nContratando\\nCampos:\\nDATA\\nCADERNO\\nSE\\u00c7\\u00c3O\\nNORMATIVA\\n\\u00d3RG\\u00c3O LOTA\\u00c7\\u00c3O\\nTIPO\\nNOME\\nRG\\nCPF\\nCARGO\\nLINK\\n9\",\n",
            "    \"page\": 2,\n",
            "    \"position\": 2\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"news\",\n",
            "    \"content\": \"Red Hat OpenShift AI\\nDocumento de Arquitetura\\nDi\\u00e1rio Oficial: Diagrama\\u00e7\\u00e3o e Extra\\u00e7\\u00e3o\\nPreparadopara:\\n1\",\n",
            "    \"page\": 2,\n",
            "    \"position\": 3\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"advertisement\",\n",
            "    \"content\": \"Ad Placeholder\",\n",
            "    \"page\": 2,\n",
            "    \"position\": \"bottom\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        pages = [page.extract_text() for page in pdf.pages]\n",
        "    return pages\n",
        "\n",
        "def preprocess_and_split_text(pages):\n",
        "    news_items = [item.strip() for page in pages for item in page.split(\"\\n\\n\") if item.strip()]\n",
        "    return news_items\n",
        "\n",
        "def generate_embeddings(news_items, model_name='all-MiniLM-L6-v2'):\n",
        "    model = SentenceTransformer(model_name)\n",
        "    embeddings = model.encode(news_items)\n",
        "    return embeddings, model\n",
        "\n",
        "def create_faiss_index(embeddings):\n",
        "    dimension = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(dimension)\n",
        "    index.add(embeddings)\n",
        "    return index\n",
        "\n",
        "def add_metadata(news_items):\n",
        "    metadata = [{\"id\": i, \"content\": news_items[i], \"length\": len(news_items[i])} for i in range(len(news_items))]\n",
        "    return metadata\n",
        "\n",
        "def search_similar_news(query, model, index, metadata, top_k=5):\n",
        "    query_embedding = model.encode([query])\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "    results = [\n",
        "        {\"content\": metadata[idx][\"content\"], \"distance\": float(dist), \"length\": metadata[idx][\"length\"]}\n",
        "        for dist, idx in zip(distances[0], indices[0])\n",
        "    ]\n",
        "    return results\n",
        "\n",
        "def optimize_layout(metadata, top_k=5):\n",
        "    # Sort news items by length (longer news first)\n",
        "    sorted_news = sorted(metadata, key=lambda x: x[\"length\"], reverse=True)\n",
        "\n",
        "    layout = []\n",
        "    for i, item in enumerate(sorted_news):\n",
        "        layout.append({\"type\": \"news\", \"content\": item[\"content\"], \"page\": i // top_k + 1, \"position\": i % top_k})\n",
        "        if (i + 1) % 3 == 0:\n",
        "            layout.append({\"type\": \"advertisement\", \"content\": \"Ad Placeholder\", \"page\": (i + 1) // top_k + 1, \"position\": \"bottom\"})\n",
        "\n",
        "    return layout\n",
        "\n",
        "def main():\n",
        "    pdf_path = \"/content/RHOAI _ Prodesp - Diário Oficial.pdf\"\n",
        "\n",
        "    print(\"Extracting text from PDF...\")\n",
        "    pages = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "    print(\"Preprocessing and splitting text...\")\n",
        "    news_items = preprocess_and_split_text(pages)\n",
        "\n",
        "    print(\"Generating embeddings...\")\n",
        "    embeddings, model = generate_embeddings(news_items)\n",
        "\n",
        "    print(\"Creating FAISS index...\")\n",
        "    index = create_faiss_index(np.array(embeddings))\n",
        "\n",
        "    print(\"Adding metadata...\")\n",
        "    metadata = add_metadata(news_items)\n",
        "\n",
        "    query = \"example query about a topic\"\n",
        "    print(\"Searching for similar news...\")\n",
        "    results = search_similar_news(query, model, index, metadata, top_k=5)\n",
        "\n",
        "    print(\"Search Results:\")\n",
        "    print(json.dumps(results, indent=2))\n",
        "\n",
        "    print(\"Optimizing layout...\")\n",
        "    layout = optimize_layout(metadata)\n",
        "\n",
        "    print(\"Layout:\")\n",
        "    print(json.dumps(layout, indent=2))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "AUVPbhFqKLqS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53c5ac6d-8cdc-48cb-d866-7fbfdaf27463"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting text from PDF...\n",
            "Preprocessing and splitting text...\n",
            "Generating embeddings...\n",
            "Creating FAISS index...\n",
            "Adding metadata...\n",
            "Searching for similar news...\n",
            "Search Results:\n",
            "[\n",
            "  {\n",
            "    \"content\": \"-Justificarasmat\\u00e9riasqueest\\u00e3odentrodamesmacolunaautomaticamente\\n10.Entreasse\\u00e7\\u00f5esdemat\\u00e9ria,incluirumtextoautomaticamentedaquebradese\\u00e7\\u00e3o\\n4.Extra\\u00e7\\u00e3o\\na. Arquitetura\\n#TODO\\n7\",\n",
            "    \"distance\": 1.64579439163208,\n",
            "    \"length\": 168\n",
            "  },\n",
            "  {\n",
            "    \"content\": \"EstruturadoJSONderetornoesperadoqueser\\u00e1geradopelaRedHat\\n{ \\\"pdf_data\\\":\\n[\\n{\\\"id\\\": \\u201cf97fb8c9-60d6-4fed-a82d-1cdf4e8be0bc\\u201d ,\\\"x\\\":50,\\\"y\\\":300,\\\"pagina\\\":1,\\\"tipo\\\":\\\"mat\\u00e9ria\\\"},\\n{\\u201cid\\u201d:\\u201c\\\",\\\"x\\\":100,\\\"y\\\":550,\\\"pagina\\\":1,\\\"tipo\\\":\\\"titulo\\\"},\\n{\\u201cid\\u201d:\\u201cd2a7e6bd-5d6d-4e1c-a747-a0ae5f1499da\\\",\\\"x\\\":100,\\\"y\\\":550,\\\"pagina\\\":1,\\\"tipo\\\":\\\"mat\\u00e9ria\\\"}\\n{\\u201cid\\u201d:\\u201c\\\",\\\"x\\\":100,\\\"y\\\":550,\\\"pagina\\\":1,\\\"tipo\\\":\\\"calhau-1\\\"}\\n]\\n}\\n\\u2014--------\\nDi\\u00e1riooficial:tamanhoA3\\n-Alinhamentodasmat\\u00e9riascomamargemsuperiorquandonaprimeiralinhainterpretando\\n\\\"Alinhamento\\\"comodist\\u00e2nciadamargemsuperior:17mm.\\n-Alinhamentodasmat\\u00e9riascomamargeminferiorquandonaultimalinha,interpretando\\\"Alinhamento\\\"\\ncomodist\\u00e2nciadamargeminferior:13mm.\\n-Alinhamentodasmat\\u00e9riascomamargemesquerdaquandonaprimeiracolunainterpretando\\n\\\"Alinhamento\\\"comodist\\u00e2nciadamargemesquerda:13mm\\n-Alinhamentodasmat\\u00e9riascomamargemdireitaquandonaultimacoluna,interpretando\\n\\\"Alinhamento\\\"comodist\\u00e2nciadamargemdireita:13mm.\\n5\",\n",
            "    \"distance\": 1.7058844566345215,\n",
            "    \"length\": 899\n",
            "  },\n",
            "  {\n",
            "    \"content\": \"Suspende\\nCertid\\u00e3ode\\u00f3bito\\nExonerando\\nDesignando\\nDesigna\\nContratando\\nCampos:\\nDATA\\nCADERNO\\nSE\\u00c7\\u00c3O\\nNORMATIVA\\n\\u00d3RG\\u00c3O LOTA\\u00c7\\u00c3O\\nTIPO\\nNOME\\nRG\\nCPF\\nCARGO\\nLINK\\n9\",\n",
            "    \"distance\": 1.8453752994537354,\n",
            "    \"length\": 147\n",
            "  },\n",
            "  {\n",
            "    \"content\": \"Contatos Red Hat\\nContatoRedHat Nome E-mail\\nAccountManager Pedro Ganem Filho pedroganem@redhat.com\\nSolutionArchitect Juarez J\\u00fanior jjunior@redhat.com\\nTerritoryServicesManager Rejane Rossi rrossi@redhat.com\\nArchitect Tarcisio Oliveira tarcisio@redhat.com\\nSSP Gabriel Sampaio gsampaio@redhat.com\\nSSP Joao Jose Silva (JJ) joao.silva@redhat.com\\nSSA Weslley Rosalem wrosalem@redhat.com\\nHist\\u00f3rico do Documento\\nVers\\u00e3o Data Respons\\u00e1vel Observa\\u00e7\\u00e3o\\n1.0 10-11-2024 Tarcisio Oliveira Elabora\\u00e7\\u00e3ododocumento\\n3\",\n",
            "    \"distance\": 1.8515489101409912,\n",
            "    \"length\": 494\n",
            "  },\n",
            "  {\n",
            "    \"content\": \"b. Protocolo\\n#TODO\\n5. #TODO\\nVmwarevsocpvirt\\nExpandirarquitetura?\\n6.#TODO\\nTermos:\\nAdmite/Admitindo\\nAposenta\\nAposentado\\nAposentadoria\\nAposentando\\nAposentar\\nDemite/Demiss\\u00e3o\\nEfetiva\\nExonera\\nExonera\\u00e7\\u00e3o\\nExpuls\\u00e3o\\nFalecidos\\nFalecimento\\nNomea\\u00e7\\u00e3o\\nNomeia/Nomeando\\nReintegra\\n8\",\n",
            "    \"distance\": 1.8648027181625366,\n",
            "    \"length\": 264\n",
            "  }\n",
            "]\n",
            "Optimizing layout...\n",
            "Layout:\n",
            "[\n",
            "  {\n",
            "    \"type\": \"news\",\n",
            "    \"content\": \"EstruturadoJSONderetornoesperadoqueser\\u00e1geradopelaRedHat\\n{ \\\"pdf_data\\\":\\n[\\n{\\\"id\\\": \\u201cf97fb8c9-60d6-4fed-a82d-1cdf4e8be0bc\\u201d ,\\\"x\\\":50,\\\"y\\\":300,\\\"pagina\\\":1,\\\"tipo\\\":\\\"mat\\u00e9ria\\\"},\\n{\\u201cid\\u201d:\\u201c\\\",\\\"x\\\":100,\\\"y\\\":550,\\\"pagina\\\":1,\\\"tipo\\\":\\\"titulo\\\"},\\n{\\u201cid\\u201d:\\u201cd2a7e6bd-5d6d-4e1c-a747-a0ae5f1499da\\\",\\\"x\\\":100,\\\"y\\\":550,\\\"pagina\\\":1,\\\"tipo\\\":\\\"mat\\u00e9ria\\\"}\\n{\\u201cid\\u201d:\\u201c\\\",\\\"x\\\":100,\\\"y\\\":550,\\\"pagina\\\":1,\\\"tipo\\\":\\\"calhau-1\\\"}\\n]\\n}\\n\\u2014--------\\nDi\\u00e1riooficial:tamanhoA3\\n-Alinhamentodasmat\\u00e9riascomamargemsuperiorquandonaprimeiralinhainterpretando\\n\\\"Alinhamento\\\"comodist\\u00e2nciadamargemsuperior:17mm.\\n-Alinhamentodasmat\\u00e9riascomamargeminferiorquandonaultimalinha,interpretando\\\"Alinhamento\\\"\\ncomodist\\u00e2nciadamargeminferior:13mm.\\n-Alinhamentodasmat\\u00e9riascomamargemesquerdaquandonaprimeiracolunainterpretando\\n\\\"Alinhamento\\\"comodist\\u00e2nciadamargemesquerda:13mm\\n-Alinhamentodasmat\\u00e9riascomamargemdireitaquandonaultimacoluna,interpretando\\n\\\"Alinhamento\\\"comodist\\u00e2nciadamargemdireita:13mm.\\n5\",\n",
            "    \"page\": 1,\n",
            "    \"position\": 0\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"news\",\n",
            "    \"content\": \"Contatos Red Hat\\nContatoRedHat Nome E-mail\\nAccountManager Pedro Ganem Filho pedroganem@redhat.com\\nSolutionArchitect Juarez J\\u00fanior jjunior@redhat.com\\nTerritoryServicesManager Rejane Rossi rrossi@redhat.com\\nArchitect Tarcisio Oliveira tarcisio@redhat.com\\nSSP Gabriel Sampaio gsampaio@redhat.com\\nSSP Joao Jose Silva (JJ) joao.silva@redhat.com\\nSSA Weslley Rosalem wrosalem@redhat.com\\nHist\\u00f3rico do Documento\\nVers\\u00e3o Data Respons\\u00e1vel Observa\\u00e7\\u00e3o\\n1.0 10-11-2024 Tarcisio Oliveira Elabora\\u00e7\\u00e3ododocumento\\n3\",\n",
            "    \"page\": 1,\n",
            "    \"position\": 1\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"news\",\n",
            "    \"content\": \"-Espa\\u00e7amentominimoentreosblocosdemat\\u00e9riasde5CM-\\nCorre\\u00e7\\u00e3o:Espa\\u00e7amentom\\u00ednimoentreasmat\\u00e9riasmaisutilizado\\u00e9deaproximadamente5MM\\n(mil\\u00edmetros)\\n-Adi\\u00e7\\u00e3odecalhauautomaticamente-Bibliotecazipadaemanexo\\n-Ocalhauser\\u00e1adicionadoautomaticamenteSE,esomenteSE,oespa\\u00e7ovagoformenorqueos\\ncalhausdispon\\u00edveis\\n-Verificarostamanhosdispon\\u00edveisdecalhaus\\nPrincipaismedidasemmil\\u00edmetrosparapublicidade\\nLxA\\n81x100\\n81x400\\n250x40\\n250x120\\n250x200\\n250x210\\n250x294\\n250x370\\n6\",\n",
            "    \"page\": 1,\n",
            "    \"position\": 2\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"advertisement\",\n",
            "    \"content\": \"Ad Placeholder\",\n",
            "    \"page\": 1,\n",
            "    \"position\": \"bottom\"\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"news\",\n",
            "    \"content\": \"1. Red Hat OpenShift Container Platform\\n2. Red Hat OpenShift AI\\n3. Diagrama\\u00e7\\u00e3o\\na. Arquitetura\\n#TODO\\nb. Protocolo\\n{ \\\"pdf_data\\\":\\n[\\n{\\\"id\\\": \\u201cf97fb8c9-60d6-4fed-a82d-1cdf4e8be0bc\\u201d , \\u201caltura\\u201d:125,\\u201clargura\\u201d:35,\\n\\\"agrupamento\\\":1},\\n{\\\"id\\\": \\u201cf97fb8c9-60d6-4fed-a82d-1cdf4e8be0bc\\u201d , \\u201caltura\\u201d:70,\\u201clargura\\u201d:40,\\n\\\"agrupamento\\\":2}\\n]\\n}\\n4\",\n",
            "    \"page\": 1,\n",
            "    \"position\": 3\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"news\",\n",
            "    \"content\": \"b. Protocolo\\n#TODO\\n5. #TODO\\nVmwarevsocpvirt\\nExpandirarquitetura?\\n6.#TODO\\nTermos:\\nAdmite/Admitindo\\nAposenta\\nAposentado\\nAposentadoria\\nAposentando\\nAposentar\\nDemite/Demiss\\u00e3o\\nEfetiva\\nExonera\\nExonera\\u00e7\\u00e3o\\nExpuls\\u00e3o\\nFalecidos\\nFalecimento\\nNomea\\u00e7\\u00e3o\\nNomeia/Nomeando\\nReintegra\\n8\",\n",
            "    \"page\": 1,\n",
            "    \"position\": 4\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"news\",\n",
            "    \"content\": \"Sum\\u00e1rio\\nSum\\u00e1rio 2\\nContatos Red Hat 3\\nHist\\u00f3rico do Documento 3\\n1. Red Hat OpenShift Container Platform 4\\n2. Red Hat OpenShift AI 4\\n3. Diagrama\\u00e7\\u00e3o 4\\n4. Extra\\u00e7\\u00e3o 5\\n5. #TODO 5\\n2\",\n",
            "    \"page\": 2,\n",
            "    \"position\": 0\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"advertisement\",\n",
            "    \"content\": \"Ad Placeholder\",\n",
            "    \"page\": 2,\n",
            "    \"position\": \"bottom\"\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"news\",\n",
            "    \"content\": \"-Justificarasmat\\u00e9riasqueest\\u00e3odentrodamesmacolunaautomaticamente\\n10.Entreasse\\u00e7\\u00f5esdemat\\u00e9ria,incluirumtextoautomaticamentedaquebradese\\u00e7\\u00e3o\\n4.Extra\\u00e7\\u00e3o\\na. Arquitetura\\n#TODO\\n7\",\n",
            "    \"page\": 2,\n",
            "    \"position\": 1\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"news\",\n",
            "    \"content\": \"Suspende\\nCertid\\u00e3ode\\u00f3bito\\nExonerando\\nDesignando\\nDesigna\\nContratando\\nCampos:\\nDATA\\nCADERNO\\nSE\\u00c7\\u00c3O\\nNORMATIVA\\n\\u00d3RG\\u00c3O LOTA\\u00c7\\u00c3O\\nTIPO\\nNOME\\nRG\\nCPF\\nCARGO\\nLINK\\n9\",\n",
            "    \"page\": 2,\n",
            "    \"position\": 2\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"news\",\n",
            "    \"content\": \"Red Hat OpenShift AI\\nDocumento de Arquitetura\\nDi\\u00e1rio Oficial: Diagrama\\u00e7\\u00e3o e Extra\\u00e7\\u00e3o\\nPreparadopara:\\n1\",\n",
            "    \"page\": 2,\n",
            "    \"position\": 3\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"advertisement\",\n",
            "    \"content\": \"Ad Placeholder\",\n",
            "    \"page\": 2,\n",
            "    \"position\": \"bottom\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "input_data = {\n",
        "    \"pdf_data\": [\n",
        "        {\"id\": \"f97fb8c9-60d6-4fed-a82d-1cdf4e8be0bc\", \"altura\": 125, \"largura\": 35, \"agrupamento\": 1},\n",
        "        {\"id\": \"f97fb8c9-60d6-4fed-a82d-1cdf4e8be0bc\", \"altura\": 70, \"largura\": 40, \"agrupamento\": 2}\n",
        "    ]\n",
        "}\n",
        "\n",
        "margin_top = 17  # mm\n",
        "margin_bottom = 13  # mm\n",
        "margin_left = 13  # mm\n",
        "margin_right = 13  # mm\n",
        "min_spacing_mm = 5  # mm\n",
        "page_height_mm = 420\n",
        "ad_sizes = [(81, 100), (250, 210)]\n",
        "\n",
        "def generate_output(input_data):\n",
        "    output_data = {\"pdf_data\": []}\n",
        "    page = 1\n",
        "    current_y = margin_top\n",
        "\n",
        "    for item in input_data[\"pdf_data\"]:\n",
        "        content_type = \"matéria\" if item[\"agrupamento\"] == 1 else \"titulo\"\n",
        "        output_data[\"pdf_data\"].append({\n",
        "            \"id\": item[\"id\"],\n",
        "            \"x\": margin_left,\n",
        "            \"y\": current_y,\n",
        "            \"pagina\": page,\n",
        "            \"tipo\": content_type\n",
        "        })\n",
        "        current_y += item[\"altura\"] + min_spacing_mm\n",
        "\n",
        "        if current_y + margin_bottom > page_height_mm:\n",
        "            page += 1\n",
        "            current_y = margin_top\n",
        "\n",
        "        for ad_width, ad_height in ad_sizes:\n",
        "            if current_y + ad_height + margin_bottom <= page_height_mm:\n",
        "                output_data[\"pdf_data\"].append({\n",
        "                    \"id\": \"calhau-placeholder\",\n",
        "                    \"x\": margin_left,\n",
        "                    \"y\": current_y,\n",
        "                    \"pagina\": page,\n",
        "                    \"tipo\": f\"calhau-{ad_width}x{ad_height}\"\n",
        "                })\n",
        "                current_y += ad_height + min_spacing_mm\n",
        "                break\n",
        "\n",
        "    return output_data\n",
        "\n",
        "structured_output = generate_output(input_data)\n",
        "\n",
        "output_path = \"structured_output.json\"\n",
        "with open(output_path, \"w\") as f:\n",
        "    json.dump(structured_output, f, indent=2)\n",
        "\n",
        "print(f\"Structured JSON output saved to {output_path}\")\n",
        "structured_output\n"
      ],
      "metadata": {
        "id": "1xuCgG-nKNcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d904993-0a59-4358-cf8f-5082c4a7064d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Structured JSON output saved to structured_output.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pdf_data': [{'id': 'f97fb8c9-60d6-4fed-a82d-1cdf4e8be0bc',\n",
              "   'x': 13,\n",
              "   'y': 17,\n",
              "   'pagina': 1,\n",
              "   'tipo': 'matéria'},\n",
              "  {'id': 'calhau-placeholder',\n",
              "   'x': 13,\n",
              "   'y': 147,\n",
              "   'pagina': 1,\n",
              "   'tipo': 'calhau-81x100'},\n",
              "  {'id': 'f97fb8c9-60d6-4fed-a82d-1cdf4e8be0bc',\n",
              "   'x': 13,\n",
              "   'y': 252,\n",
              "   'pagina': 1,\n",
              "   'tipo': 'titulo'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import json\n",
        "\n",
        "margin_top = 17  # mm\n",
        "margin_bottom = 13  # mm\n",
        "margin_left = 13  # mm\n",
        "margin_right = 13  # mm\n",
        "min_spacing_mm = 5  # mm\n",
        "page_height_mm = 420\n",
        "ad_sizes = [(81, 100), (250, 210)]\n",
        "\n",
        "def extract_pdf_data(pdf_path):\n",
        "    extracted_data = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page_number, page in enumerate(pdf.pages, start=1):\n",
        "            text = page.extract_text()\n",
        "            if not text:\n",
        "                continue\n",
        "            # Split text into blocks for processing\n",
        "            for idx, block in enumerate(text.split(\"\\n\\n\")):\n",
        "                extracted_data.append({\n",
        "                    \"id\": f\"block-{page_number}-{idx}\",\n",
        "                    \"content\": block.strip(),\n",
        "                    \"altura\": len(block) * 0.1,\n",
        "                    \"largura\": 200,\n",
        "                    \"agrupamento\": 1 if idx % 2 == 0 else 2\n",
        "                })\n",
        "    return extracted_data\n",
        "\n",
        "def generate_output(pdf_data):\n",
        "    output_data = {\"pdf_data\": []}\n",
        "    page = 1\n",
        "    current_y = margin_top\n",
        "\n",
        "    for item in pdf_data:\n",
        "        content_type = \"matéria\" if item[\"agrupamento\"] == 1 else \"titulo\"\n",
        "        output_data[\"pdf_data\"].append({\n",
        "            \"id\": item[\"id\"],\n",
        "            \"x\": margin_left,\n",
        "            \"y\": current_y,\n",
        "            \"pagina\": page,\n",
        "            \"tipo\": content_type\n",
        "        })\n",
        "        current_y += item[\"altura\"] + min_spacing_mm\n",
        "\n",
        "        if current_y + margin_bottom > page_height_mm:\n",
        "            page += 1\n",
        "            current_y = margin_top\n",
        "\n",
        "        for ad_width, ad_height in ad_sizes:\n",
        "            if current_y + ad_height + margin_bottom <= page_height_mm:\n",
        "                output_data[\"pdf_data\"].append({\n",
        "                    \"id\": \"calhau-placeholder\",\n",
        "                    \"x\": margin_left,\n",
        "                    \"y\": current_y,\n",
        "                    \"pagina\": page,\n",
        "                    \"tipo\": f\"calhau-{ad_width}x{ad_height}\"\n",
        "                })\n",
        "                current_y += ad_height + min_spacing_mm\n",
        "                break\n",
        "\n",
        "    return output_data\n",
        "\n",
        "pdf_path = \"/content/RHOAI _ Prodesp - Diário Oficial.pdf\"\n",
        "\n",
        "print(\"Extracting data from the PDF...\")\n",
        "pdf_data = extract_pdf_data(pdf_path)\n",
        "\n",
        "print(\"Generating structured JSON output...\")\n",
        "structured_output = generate_output(pdf_data)\n",
        "\n",
        "output_path = \"structured_output.json\"\n",
        "with open(output_path, \"w\") as f:\n",
        "    json.dump(structured_output, f, indent=2)\n",
        "\n",
        "print(f\"Structured JSON output saved to {output_path}\")\n",
        "structured_output\n"
      ],
      "metadata": {
        "id": "k3T-zhObKOmX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81cdb774-2fd3-4a7f-b6c4-b4413cd67046"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data from the PDF...\n",
            "Generating structured JSON output...\n",
            "Structured JSON output saved to structured_output.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pdf_data': [{'id': 'block-1-0',\n",
              "   'x': 13,\n",
              "   'y': 17,\n",
              "   'pagina': 1,\n",
              "   'tipo': 'matéria'},\n",
              "  {'id': 'calhau-placeholder',\n",
              "   'x': 13,\n",
              "   'y': 32.1,\n",
              "   'pagina': 1,\n",
              "   'tipo': 'calhau-81x100'},\n",
              "  {'id': 'block-2-0', 'x': 13, 'y': 137.1, 'pagina': 1, 'tipo': 'matéria'},\n",
              "  {'id': 'calhau-placeholder',\n",
              "   'x': 13,\n",
              "   'y': 159.4,\n",
              "   'pagina': 1,\n",
              "   'tipo': 'calhau-81x100'},\n",
              "  {'id': 'block-3-0', 'x': 13, 'y': 264.4, 'pagina': 1, 'tipo': 'matéria'},\n",
              "  {'id': 'block-4-0',\n",
              "   'x': 13,\n",
              "   'y': 318.79999999999995,\n",
              "   'pagina': 1,\n",
              "   'tipo': 'matéria'},\n",
              "  {'id': 'block-5-0',\n",
              "   'x': 13,\n",
              "   'y': 355.59999999999997,\n",
              "   'pagina': 1,\n",
              "   'tipo': 'matéria'},\n",
              "  {'id': 'calhau-placeholder',\n",
              "   'x': 13,\n",
              "   'y': 17,\n",
              "   'pagina': 2,\n",
              "   'tipo': 'calhau-81x100'},\n",
              "  {'id': 'block-6-0', 'x': 13, 'y': 122, 'pagina': 2, 'tipo': 'matéria'},\n",
              "  {'id': 'calhau-placeholder',\n",
              "   'x': 13,\n",
              "   'y': 170.9,\n",
              "   'pagina': 2,\n",
              "   'tipo': 'calhau-81x100'},\n",
              "  {'id': 'block-7-0', 'x': 13, 'y': 275.9, 'pagina': 2, 'tipo': 'matéria'},\n",
              "  {'id': 'calhau-placeholder',\n",
              "   'x': 13,\n",
              "   'y': 297.7,\n",
              "   'pagina': 2,\n",
              "   'tipo': 'calhau-81x100'},\n",
              "  {'id': 'block-8-0', 'x': 13, 'y': 402.7, 'pagina': 2, 'tipo': 'matéria'},\n",
              "  {'id': 'calhau-placeholder',\n",
              "   'x': 13,\n",
              "   'y': 17,\n",
              "   'pagina': 3,\n",
              "   'tipo': 'calhau-81x100'},\n",
              "  {'id': 'block-9-0', 'x': 13, 'y': 122, 'pagina': 3, 'tipo': 'matéria'},\n",
              "  {'id': 'calhau-placeholder',\n",
              "   'x': 13,\n",
              "   'y': 141.7,\n",
              "   'pagina': 3,\n",
              "   'tipo': 'calhau-81x100'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI, File, UploadFile\n",
        "from fastapi.responses import JSONResponse\n",
        "import pdfplumber\n",
        "import json\n",
        "import os\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "margin_top = 17  # mm\n",
        "margin_bottom = 13  # mm\n",
        "margin_left = 13  # mm\n",
        "margin_right = 13  # mm\n",
        "min_spacing_mm = 5  # mm\n",
        "page_height_mm = 420\n",
        "ad_sizes = [(81, 100), (250, 210)]\n",
        "\n",
        "def extract_pdf_data(pdf_path):\n",
        "    extracted_data = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page_number, page in enumerate(pdf.pages, start=1):\n",
        "            text = page.extract_text()\n",
        "            if not text:\n",
        "                continue\n",
        "            for idx, block in enumerate(text.split(\"\\n\\n\")):\n",
        "                extracted_data.append({\n",
        "                    \"id\": f\"block-{page_number}-{idx}\",\n",
        "                    \"content\": block.strip(),\n",
        "                    \"altura\": len(block) * 0.1,\n",
        "                    \"largura\": 200,\n",
        "                    \"agrupamento\": 1 if idx % 2 == 0 else 2\n",
        "                })\n",
        "    return extracted_data\n",
        "\n",
        "def generate_output(pdf_data):\n",
        "    output_data = {\"pdf_data\": []}\n",
        "    page = 1\n",
        "    current_y = margin_top\n",
        "\n",
        "    for item in pdf_data:\n",
        "        content_type = \"matéria\" if item[\"agrupamento\"] == 1 else \"titulo\"\n",
        "        output_data[\"pdf_data\"].append({\n",
        "            \"id\": item[\"id\"],\n",
        "            \"x\": margin_left,\n",
        "            \"y\": current_y,\n",
        "            \"pagina\": page,\n",
        "            \"tipo\": content_type\n",
        "        })\n",
        "        current_y += item[\"altura\"] + min_spacing_mm\n",
        "\n",
        "        if current_y + margin_bottom > page_height_mm:\n",
        "            page += 1\n",
        "            current_y = margin_top\n",
        "\n",
        "        for ad_width, ad_height in ad_sizes:\n",
        "            if current_y + ad_height + margin_bottom <= page_height_mm:\n",
        "                output_data[\"pdf_data\"].append({\n",
        "                    \"id\": \"calhau-placeholder\",\n",
        "                    \"x\": margin_left,\n",
        "                    \"y\": current_y,\n",
        "                    \"pagina\": page,\n",
        "                    \"tipo\": f\"calhau-{ad_width}x{ad_height}\"\n",
        "                })\n",
        "                current_y += ad_height + min_spacing_mm\n",
        "                break\n",
        "\n",
        "    return output_data\n",
        "\n",
        "@app.post(\"/upload-pdf/\")\n",
        "async def upload_pdf(file: UploadFile = File(...)):\n",
        "    pdf_path = f\"./{file.filename}\"\n",
        "    with open(pdf_path, \"wb\") as f:\n",
        "        f.write(await file.read())\n",
        "\n",
        "    try:\n",
        "        pdf_data = extract_pdf_data(pdf_path)\n",
        "\n",
        "        structured_output = generate_output(pdf_data)\n",
        "\n",
        "        output_path = f\"./{os.path.splitext(file.filename)[0]}_output.json\"\n",
        "        with open(output_path, \"w\") as f:\n",
        "            json.dump(structured_output, f, indent=2)\n",
        "\n",
        "        return JSONResponse(content=structured_output)\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "    finally:\n",
        "        if os.path.exists(pdf_path):\n",
        "            os.remove(pdf_path)\n",
        "\n",
        "# To run the API server:\n",
        "# Use the command: uvicorn <filename>:app --reload\n"
      ],
      "metadata": {
        "id": "3qLmIfH8KP4S"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI, File, UploadFile\n",
        "from fastapi.responses import JSONResponse\n",
        "import pdfplumber\n",
        "import json\n",
        "import os\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "\n",
        "# Initialize FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "# Constants for layout rules\n",
        "margin_top = 17  # mm\n",
        "margin_bottom = 13  # mm\n",
        "margin_left = 13  # mm\n",
        "margin_right = 13  # mm\n",
        "min_spacing_mm = 5  # mm\n",
        "page_height_mm = 420  # Approx height of A3 in mm\n",
        "ad_sizes = [(81, 100), (250, 210)]  # Example sizes in mm\n",
        "\n",
        "# Extract text and preprocess data from PDF\n",
        "def extract_pdf_data(pdf_path):\n",
        "    extracted_data = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page_number, page in enumerate(pdf.pages, start=1):\n",
        "            text = page.extract_text()\n",
        "            if not text:\n",
        "                continue\n",
        "            # Split text into blocks for processing\n",
        "            for idx, block in enumerate(text.split(\"\\n\\n\")):\n",
        "                extracted_data.append({\n",
        "                    \"id\": f\"block-{page_number}-{idx}\",\n",
        "                    \"content\": block.strip(),\n",
        "                    \"altura\": len(block) * 0.1,  # Mock height based on content length\n",
        "                    \"largura\": 200,  # Arbitrary width\n",
        "                    \"agrupamento\": 1 if idx % 2 == 0 else 2  # Alternate grouping\n",
        "                })\n",
        "    return extracted_data\n",
        "\n",
        "# Generate the expected JSON output with alignment and spacing rules\n",
        "def generate_output(pdf_data):\n",
        "    output_data = {\"pdf_data\": []}\n",
        "    page = 1\n",
        "    current_y = margin_top  # Start at the top margin\n",
        "\n",
        "    for item in pdf_data:\n",
        "        # Add an entry for the main content\n",
        "        content_type = \"matéria\" if item[\"agrupamento\"] == 1 else \"titulo\"\n",
        "        output_data[\"pdf_data\"].append({\n",
        "            \"id\": item[\"id\"],\n",
        "            \"x\": margin_left,  # Always align to left margin\n",
        "            \"y\": current_y,\n",
        "            \"pagina\": page,\n",
        "            \"tipo\": content_type\n",
        "        })\n",
        "        # Update Y position considering the height and spacing\n",
        "        current_y += item[\"altura\"] + min_spacing_mm\n",
        "\n",
        "        # Check if a new page is needed\n",
        "        if current_y + margin_bottom > page_height_mm:\n",
        "            page += 1\n",
        "            current_y = margin_top\n",
        "\n",
        "        # Add calhau (ad placeholder) if space permits\n",
        "        for ad_width, ad_height in ad_sizes:\n",
        "            if current_y + ad_height + margin_bottom <= page_height_mm:\n",
        "                output_data[\"pdf_data\"].append({\n",
        "                    \"id\": \"calhau-placeholder\",\n",
        "                    \"x\": margin_left,\n",
        "                    \"y\": current_y,\n",
        "                    \"pagina\": page,\n",
        "                    \"tipo\": f\"calhau-{ad_width}x{ad_height}\"\n",
        "                })\n",
        "                current_y += ad_height + min_spacing_mm\n",
        "                break\n",
        "\n",
        "    return output_data\n",
        "\n",
        "@app.post(\"/upload-pdf/\")\n",
        "async def upload_pdf(file: UploadFile = File(...)):\n",
        "    # Save the uploaded file\n",
        "    pdf_path = f\"./{file.filename}\"\n",
        "    with open(pdf_path, \"wb\") as f:\n",
        "        f.write(await file.read())\n",
        "\n",
        "    try:\n",
        "        # Extract data from the PDF\n",
        "        pdf_data = extract_pdf_data(pdf_path)\n",
        "\n",
        "        # Generate the structured output\n",
        "        structured_output = generate_output(pdf_data)\n",
        "\n",
        "        # Save the structured JSON output\n",
        "        output_path = f\"./{os.path.splitext(file.filename)[0]}_output.json\"\n",
        "        with open(output_path, \"w\") as f:\n",
        "            json.dump(structured_output, f, indent=2)\n",
        "\n",
        "        # Return the structured output as response\n",
        "        return JSONResponse(content=structured_output)\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "    finally:\n",
        "        # Clean up: Remove the uploaded file\n",
        "        if os.path.exists(pdf_path):\n",
        "            os.remove(pdf_path)\n",
        "\n",
        "# Run the server in Jupyter Notebook\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()  # Allow nested event loops in Jupyter\n",
        "\n",
        "# Start the FastAPI server\n",
        "print(\"Starting FastAPI server...\")\n",
        "uvicorn.run(app, host=\"127.0.0.1\", port=8000)"
      ],
      "metadata": {
        "id": "tKSyltt4KRNy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"http://127.0.0.1:8000/upload-pdf/\"\n",
        "files = {\"file\": open(\"RHOAI _ Prodesp - Diário Oficial.pdf\", \"rb\")}\n",
        "response = requests.post(url, files=files)\n",
        "\n",
        "print(response.json())"
      ],
      "metadata": {
        "id": "1fsFekLiKSiR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math\n",
        "import json\n",
        "\n",
        "# Constantes de layout\n",
        "MARGIN_TOP = 17  # mm\n",
        "MARGIN_BOTTOM = 13  # mm\n",
        "MARGIN_LEFT = 13  # mm\n",
        "MARGIN_RIGHT = 13  # mm\n",
        "MIN_SPACING_MM = 5  # mm\n",
        "PAGE_HEIGHT_MM = 420  # mm (altura de uma página A3)\n",
        "PAGE_WIDTH_MM = 297  # mm (largura de uma página A3)\n",
        "AD_SIZES = [(81, 100), (250, 210)]  # Exemplos de anúncios\n",
        "\n",
        "# Função de custo\n",
        "def calculate_cost(layout):\n",
        "    \"\"\"\n",
        "    Calcula o custo baseado em:\n",
        "    - Espaços vazios: Quanto menos espaço desperdiçado, menor o custo.\n",
        "    - Páginas usadas: Menos páginas, menor custo.\n",
        "    \"\"\"\n",
        "    unused_space = 0\n",
        "    total_pages = max(block['pagina'] for block in layout) + 1\n",
        "    for page in range(total_pages):\n",
        "        page_blocks = [b for b in layout if b['pagina'] == page]\n",
        "        used_space = sum(b['altura'] + MIN_SPACING_MM for b in page_blocks)\n",
        "        unused_space += PAGE_HEIGHT_MM - used_space\n",
        "    return total_pages * 100 + unused_space\n",
        "\n",
        "# Geração inicial do layout\n",
        "def generate_initial_layout(blocks):\n",
        "    layout = []\n",
        "    page = 0\n",
        "    current_y = MARGIN_TOP\n",
        "    for block in blocks:\n",
        "        if current_y + block['altura'] + MARGIN_BOTTOM > PAGE_HEIGHT_MM:\n",
        "            page += 1\n",
        "            current_y = MARGIN_TOP\n",
        "        layout.append({\n",
        "            \"id\": block['id'],\n",
        "            \"x\": MARGIN_LEFT,\n",
        "            \"y\": current_y,\n",
        "            \"pagina\": page,\n",
        "            \"tipo\": block.get('tipo', 'matéria'),\n",
        "            \"altura\": block['altura']\n",
        "        })\n",
        "        current_y += block['altura'] + MIN_SPACING_MM\n",
        "    return layout\n",
        "\n",
        "# Perturbação (vizinho)\n",
        "def perturb_layout(layout):\n",
        "    new_layout = layout[:]\n",
        "    idx1, idx2 = random.sample(range(len(new_layout)), 2)\n",
        "    new_layout[idx1], new_layout[idx2] = new_layout[idx2], new_layout[idx1]\n",
        "    return new_layout\n",
        "\n",
        "# Simulated Annealing\n",
        "def simulated_annealing(blocks, initial_temp, cooling_rate, max_iterations):\n",
        "    current_layout = generate_initial_layout(blocks)\n",
        "    current_cost = calculate_cost(current_layout)\n",
        "    best_layout = current_layout[:]\n",
        "    best_cost = current_cost\n",
        "\n",
        "    temperature = initial_temp\n",
        "\n",
        "    for iteration in range(max_iterations):\n",
        "        new_layout = perturb_layout(current_layout)\n",
        "        new_cost = calculate_cost(new_layout)\n",
        "        delta = new_cost - current_cost\n",
        "\n",
        "        # Aceitação baseada na temperatura\n",
        "        if delta < 0 or random.random() < math.exp(-delta / temperature):\n",
        "            current_layout = new_layout\n",
        "            current_cost = new_cost\n",
        "            if current_cost < best_cost:\n",
        "                best_layout = current_layout[:]\n",
        "                best_cost = current_cost\n",
        "\n",
        "        # Resfriamento\n",
        "        temperature *= cooling_rate\n",
        "\n",
        "        # Print de progresso\n",
        "        if iteration % 100 == 0:\n",
        "            print(f\"Iteração {iteration}, Custo Atual: {current_cost}, Melhor Custo: {best_cost}\")\n",
        "\n",
        "    return best_layout, best_cost\n",
        "\n",
        "# Dados de entrada fictícios\n",
        "blocks = [\n",
        "    {\"id\": f\"block-{i}\", \"altura\": random.randint(50, 150), \"tipo\": \"matéria\"} for i in range(20)\n",
        "]\n",
        "\n",
        "# Execução do Simulated Annealing\n",
        "initial_temp = 1000\n",
        "cooling_rate = 0.95\n",
        "max_iterations = 1000\n",
        "\n",
        "print(\"Executando Simulated Annealing para diagramação...\")\n",
        "optimized_layout, optimized_cost = simulated_annealing(blocks, initial_temp, cooling_rate, max_iterations)\n",
        "\n",
        "# Saída em JSON\n",
        "output = {\"pdf_data\": optimized_layout}\n",
        "output_path = \"optimized_layout.json\"\n",
        "with open(output_path, \"w\") as f:\n",
        "    json.dump(output, f, indent=2)\n",
        "\n",
        "print(f\"Layout otimizado salvo em {output_path}\")\n"
      ],
      "metadata": {
        "id": "lkSLdTKCSjTJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a6ce09-f1a4-4e6f-c8a1-cd2c02b67686"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executando Simulated Annealing para diagramação...\n",
            "Iteração 0, Custo Atual: 1401, Melhor Custo: 1401\n",
            "Iteração 100, Custo Atual: 1401, Melhor Custo: 1401\n",
            "Iteração 200, Custo Atual: 1401, Melhor Custo: 1401\n",
            "Iteração 300, Custo Atual: 1401, Melhor Custo: 1401\n",
            "Iteração 400, Custo Atual: 1401, Melhor Custo: 1401\n",
            "Iteração 500, Custo Atual: 1401, Melhor Custo: 1401\n",
            "Iteração 600, Custo Atual: 1401, Melhor Custo: 1401\n",
            "Iteração 700, Custo Atual: 1401, Melhor Custo: 1401\n",
            "Iteração 800, Custo Atual: 1401, Melhor Custo: 1401\n",
            "Iteração 900, Custo Atual: 1401, Melhor Custo: 1401\n",
            "Layout otimizado salvo em optimized_layout.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation"
      ],
      "metadata": {
        "id": "mSDQuV3SWl68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import json\n",
        "import re\n",
        "from fastapi import FastAPI, File, UploadFile\n",
        "from fastapi.responses import JSONResponse\n",
        "\n",
        "# Layout Constants\n",
        "MARGINS = {\"top\": 17, \"bottom\": 13, \"left\": 13, \"right\": 13}  # mm\n",
        "PAGE_HEIGHT_MM = 420  # A3 Height\n",
        "MIN_SPACING_MM = 5  # Minimum spacing between blocks\n",
        "AD_SIZES = [(81, 100), (250, 210)]  # Ad dimensions (width, height)\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "def extract_pdf_blocks(pdf_path):\n",
        "    \"\"\"Extract content blocks from the PDF.\"\"\"\n",
        "    extracted_blocks = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page_idx, page in enumerate(pdf.pages):\n",
        "            text = page.extract_text()\n",
        "            if not text:\n",
        "                continue\n",
        "            for idx, block in enumerate(text.split(\"\\n\\n\")):\n",
        "                extracted_blocks.append({\n",
        "                    \"id\": f\"block-{page_idx}-{idx}\",\n",
        "                    \"content\": block.strip(),\n",
        "                    \"altura\": len(block) * 0.1,  # Estimate height\n",
        "                    \"pagina\": page_idx + 1\n",
        "                })\n",
        "    return extracted_blocks\n",
        "\n",
        "def auto_layout(blocks):\n",
        "    \"\"\"Generate layout JSON with alignment and ads.\"\"\"\n",
        "    layout = []\n",
        "    current_y = MARGINS[\"top\"]\n",
        "    page = 1\n",
        "\n",
        "    for block in blocks:\n",
        "        layout.append({\n",
        "            \"id\": block[\"id\"],\n",
        "            \"x\": MARGINS[\"left\"],\n",
        "            \"y\": current_y,\n",
        "            \"pagina\": page,\n",
        "            \"tipo\": \"matéria\"\n",
        "        })\n",
        "        current_y += block[\"altura\"] + MIN_SPACING_MM\n",
        "        if current_y + MARGINS[\"bottom\"] > PAGE_HEIGHT_MM:\n",
        "            page += 1\n",
        "            current_y = MARGINS[\"top\"]\n",
        "\n",
        "        # Add ads if space allows\n",
        "        for ad_width, ad_height in AD_SIZES:\n",
        "            if current_y + ad_height + MARGINS[\"bottom\"] <= PAGE_HEIGHT_MM:\n",
        "                layout.append({\n",
        "                    \"id\": \"calhau-placeholder\",\n",
        "                    \"x\": MARGINS[\"left\"],\n",
        "                    \"y\": current_y,\n",
        "                    \"pagina\": page,\n",
        "                    \"tipo\": f\"calhau-{ad_width}x{ad_height}\"\n",
        "                })\n",
        "                current_y += ad_height + MIN_SPACING_MM\n",
        "                break\n",
        "\n",
        "    return layout\n",
        "\n",
        "@app.post(\"/upload-pdf/\")\n",
        "async def upload_pdf(file: UploadFile = File(...)):\n",
        "    \"\"\"Upload PDF and return structured JSON.\"\"\"\n",
        "    pdf_path = f\"./{file.filename}\"\n",
        "    with open(pdf_path, \"wb\") as f:\n",
        "        f.write(await file.read())\n",
        "\n",
        "    try:\n",
        "        blocks = extract_pdf_blocks(pdf_path)\n",
        "        structured_layout = auto_layout(blocks)\n",
        "        return JSONResponse(content={\"pdf_data\": structured_layout})\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "    finally:\n",
        "        os.remove(pdf_path)\n",
        "\n",
        "# Start API server\n"
      ],
      "metadata": {
        "id": "JTPzvgwUUHsk"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}